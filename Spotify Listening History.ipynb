{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### Importing required libraries and Join Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "I need to join all the json files that hold my personal Spotify listening history. This data can be requested from Spotify and they will send it to you within 20-30 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import glob\n",
    "import pytz\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = r'/Users/DataAnalyst/Desktop/Spotify History Project/Spotify Data'\n",
    "json_pattern = os.path.join(directory, '*.json')\n",
    "file_list = glob.glob(json_pattern)\n",
    "\n",
    "dfs = [pd.json_normalize(json.load(open(file))) for file in file_list]\n",
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Dropping irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['username', \n",
    " 'ip_addr_decrypted', \n",
    " 'user_agent_decrypted', \n",
    " 'episode_name',\n",
    " 'episode_show_name',\n",
    " 'spotify_episode_uri',\n",
    " 'offline',\n",
    " 'offline_timestamp',\n",
    " 'incognito_mode',\n",
    " 'skipped',\n",
    " 'shuffle'\n",
    " ]\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Updating the column names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = []\n",
    "for column in df.columns:\n",
    "    column_list.append(f\"'{column}':'',\")\n",
    "print('\\n'.join(column_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_col_names = {\n",
    "'ts':'timestamp',\n",
    "'ms_played':'duration_ms',\n",
    "'conn_country':'country_played',\n",
    "'master_metadata_track_name':'track_name',\n",
    "'master_metadata_album_artist_name':'artist_name',\n",
    "'master_metadata_album_album_name':'album_name',\n",
    "'spotify_track_uri':'track_uri',  \n",
    "}\n",
    "df = df.rename(columns=updated_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Filter for desired Years & Handle Empty Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "As I am doing this analysis for 2019 - 2022 I need to filter out the years.\n",
    "\n",
    "I need to create a new row for the Year based off the timestamp (I will breakdown the timestamp futher later on\n",
    "once I handle the timezone conversions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the timestamp column to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)\n",
    "df['year'] = df['timestamp'].dt.year\n",
    "years_to_keep = [2019, 2020, 2021, 2022]\n",
    "df = df[df['year'].isin(years_to_keep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows = df['track_name'].isnull()\n",
    "nan_rows.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "These were the rows where I had podcast data. I can drop these rows as I am only doing analysis on songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['track_name'], inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Clean track_uri column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "I need to clean the rows so that it just the track uri value, this will be used later on when I pull data from spotify's API to give me more data on the tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['uri'] = df['track_uri'].str.split(':',2).str[2]\n",
    "df.drop('track_uri', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### Clean Platform Type Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_platforms = df['platform'].unique()\n",
    "print('\\n'.join(unique_platforms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_counts = df['platform'].value_counts()\n",
    "print(unique_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['platform'].str.contains('iOS|ios'), 'platform'] = 'iPhone'\n",
    "df.loc[~df['platform'].str.contains('iPhone'), 'platform'] = 'Computer'\n",
    "unique_counts = df['platform'].value_counts()\n",
    "print(unique_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_counts = df['platform'].value_counts()\n",
    "percentage = unique_counts / unique_counts.sum() * 100\n",
    "percentage_formatted = percentage.apply(lambda x: f\"{x:.1f}%\")\n",
    "print(percentage_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'platform': 'platform_played_on'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### Filtereting out songs skipped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "I often skip songs after a few seconds of it coming on shuffle. For the purpose of this anlysis I will assume any track duration of less than one minute will not count as a stream. This is a fair assumption as it is very uncommon for a song to have a total duration of less than one minute (After looking through all 3,200 liked songs on my Spotify I only had a duration of less than one minute - it was the 42 second song - The Lovley Linda by Paul McCartney. So this song will be excluded from the data set (Sorry Paul!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "First, I need to format the duration_ms column into minutes, then drops all rows with a duration > 1 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration_listened'] = (df['duration_ms'] / 60000)\n",
    "df = df.drop(columns='duration_ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "less_than_1_min = (df['duration_listened'] < 1.00).sum()\n",
    "greater_than_1_min = (df['duration_listened'] > 1.00).sum()\n",
    "\n",
    "print(\"Counts of rows less than 1 minute:\", less_than_1_min)\n",
    "print(\"Counts of rows greater than 1 minute:\", greater_than_1_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['duration_listened'] >= 1.00]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "### Breakding down/Converting the timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "Because I want to do analysis on listens by the hour of the day, I need to ensure I convert the timestamps into the appropaite timezone based on where I played the track. In the data provided by Spotify it provides a timestamp in the UTC timezone so I must convert this the relevant country timezone the song was streamed in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "First, I will breakdown the timestamp into Year, so I can see the percentage of how many songs I played in each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_counts = df.groupby('country_played').size()\n",
    "\n",
    "percentage_counts = grouped_counts.div(grouped_counts.sum()) * 100\n",
    "percentage_formatted = percentage_counts.apply(lambda x: f\"{x:.1f}%\")\n",
    "print(percentage_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "Then I converted the timestamps to the appropriate timezone based on the country the track was played in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_countries = df['country_played'].unique()\n",
    "country_list = []\n",
    "for country in unique_countries:\n",
    "    country_list.append(f\"'{country}':'',\")\n",
    "print('\\n'.join(country_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy pasting the outfrom from above to save time, I then mapped each country code to its respective timezone\n",
    "country_timezones = {\n",
    "    'AU': 'Australia/Melbourne',\n",
    "    'US': 'America/New_York',\n",
    "    'ES': 'Europe/Madrid',\n",
    "    'ID': 'Asia/Jakarta',\n",
    "    'GB': 'Europe/London',\n",
    "    'JP': 'Asia/Tokyo',\n",
    "    'HK': 'Asia/Hong_Kong',\n",
    "    'FR': 'Europe/Paris',\n",
    "    'HU': 'Europe/Budapest',\n",
    "    'SE': 'Europe/Stockholm',\n",
    "    'PT': 'Europe/Lisbon',\n",
    "    'NL': 'Europe/Amsterdam',\n",
    "    'AE': 'Asia/Dubai',\n",
    "    'BE': 'Europe/Brussels',\n",
    "    'DE': 'Europe/Berlin',\n",
    "    'ZZ': 'UTC'\n",
    "}\n",
    "\n",
    "df['timestamp'] = df.apply(lambda row: row['timestamp'].astimezone(pytz.timezone(country_timezones.get(row['country_played']))), axis=1)\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "The timestamp values were converted to the correct timezone, but when I converted them to datetime they went back to the UTC timezone. To deal with this is converted the data type to string and then pulled my desired values for the year, month, day and hour columns using string indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = df['timestamp'].astype(str)\n",
    "\n",
    "df['year'] = df['timestamp'].str[:4]\n",
    "df['month'] = df['timestamp'].str[5:7]\n",
    "df['day'] = df['timestamp'].str[8:10]\n",
    "df['hour'] = df['timestamp'].str[11:13]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "### Moving year column & removing timestamp column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_column = df.pop('year')\n",
    "df.insert(df.columns.get_loc('duration_listened') + 1, 'year', year_column)\n",
    "df = df.drop(columns=['timestamp'])\n",
    "df.rename_axis('index', inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "### Saving my dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/DataAnalyst/Desktop/Spotify Listening History 2019 - 2022.csv\"\n",
    "df.to_csv(file_path, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "### Create new datafram for track URI's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_uris = df['uri'].unique()\n",
    "df_uris = pd.DataFrame({'uri': unique_uris})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uris.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "### Gathering additional data ultilizing Spotify's API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "I need to using Spotify's API to gather additional data on audo features, song duration and release date which I will use in my dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://accounts.spotify.com/api/token'\n",
    "\n",
    "auth_response = requests.post(url, {\n",
    "    'grant_type': 'client_credentials',\n",
    "    'client_id': 'client_id_number',\n",
    "    'client_secret': 'client_secret_number',\n",
    "})\n",
    "\n",
    "auth_response_data = auth_response.json()\n",
    "\n",
    "access_token = auth_response_data['access_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'Authorization': 'Bearer {token}'.format(token=access_token)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://api.spotify.com/v1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_features(uri):\n",
    "    url = f'{base_url}audio-features/{uri}'\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        audio_features = response.json()\n",
    "        selected_features = {feature: audio_features[feature] for feature in ['acousticness', \n",
    "                                                                              'danceability', \n",
    "                                                                              'energy', \n",
    "                                                                              'instrumentalness',\n",
    "                                                                              'key', \n",
    "                                                                              'liveness', \n",
    "                                                                              'loudness', \n",
    "                                                                              'mode',\n",
    "                                                                              'speechiness',\n",
    "                                                                              'tempo', \n",
    "                                                                              'time_signature',\n",
    "                                                                              'valence']}\n",
    "        return selected_features\n",
    "    else:\n",
    "        print(f\"Error getting audio features for URI '{uri}': {response.content}\")\n",
    "        return None\n",
    "\n",
    "# A dictionary to store the audio features for each uri\n",
    "audio_features_dict = {}\n",
    "\n",
    "# Iterate over each uri in the df_uris\n",
    "for uri in df_uris['uri']:\n",
    "    audio_features = get_audio_features(uri)\n",
    "    if audio_features:\n",
    "        audio_features_dict[uri] = audio_features\n",
    "        \n",
    "# I need to convert dictionary into dataframe with uri as the first column\n",
    "audio_features_dict = pd.DataFrame.from_dict(audio_features_dict, orient='index')\n",
    "audio_features_dict.insert(0, 'uri', audio_features_dict.index)\n",
    "audio_features_dict.reset_index(inplace=True, drop=True)\n",
    "\n",
    "audio_features_dict.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "### EDA & Cleaning of Additional Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_dict.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_dict.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_dict.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "I only want to assign one Key to the key value, so when there are enharmonic equivalents such as in key value 1, I will for the purpose of my analysis just use the sharp keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "pitch_class_dict = {\n",
    "    0: 'C',\n",
    "    1: 'C♯, D♭',\n",
    "    2: 'D',\n",
    "    3: 'D♯, E♭',\n",
    "    4: 'E',\n",
    "    5: 'F',\n",
    "    6: 'F♯, G♭',\n",
    "    7: 'G',\n",
    "    8: 'G♯, A♭',\n",
    "    9: 'A',\n",
    "    10: 'A♯, B♭',\n",
    "    11: 'B'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_class_dict = {\n",
    "    0: 'C',\n",
    "    1: 'C♯',\n",
    "    2: 'D',\n",
    "    3: 'D♯',\n",
    "    4: 'E',\n",
    "    5: 'F',\n",
    "    6: 'F♯',\n",
    "    7: 'G',\n",
    "    8: 'G♯',\n",
    "    9: 'A',\n",
    "    10: 'A♯',\n",
    "    11: 'B'\n",
    "}\n",
    "\n",
    "audio_features_dict['key'] = audio_features_dict['key'].map(pitch_class_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "The time_signature column represents the notational convention to specify how many beats are in each bar.  The time signature ranges from 3 to 7 indicating time signatures of \"3/4\", to \"7/4\". I want to change these numercial values to the actual time signatures eg 4 = 4/4 for ease of readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_signature_dict = {\n",
    "    3: '3/4',\n",
    "    4: '4/4',\n",
    "    5: '5/4',\n",
    "    6: '6/4',\n",
    "    7: '7/4'\n",
    "}\n",
    "audio_features_dict['time_signature'] = audio_features_dict['time_signature'].map(time_signature_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "The mode column indicates the modality (major or minor) of a track and in the data from Spotify major is represented by 1 and minor is 0. I want to change the numercial encoding to the catergory names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_dict['mode'] = audio_features_dict['mode'].replace({0:'minor', 1:'major'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_dict.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "### Saving the Audio Features Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path and name for the CSV file\n",
    "file_path = \"/Users/DataAnalyst/Desktop/track_audio_features.csv\"\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "audio_features_dict.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_dict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_dict.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "### Using Spotify's API to get dataframe for song duration & release date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track_info(uri):\n",
    "    url = f'{base_url}tracks/{uri}'\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        track_info = response.json()\n",
    "        selected_info = {'duration_ms': track_info['duration_ms'],\n",
    "                        'release_date': track_info['album']['release_date']}\n",
    "        return selected_info\n",
    "    else:\n",
    "        print(f\"Error getting track_info for URI '{uri}': {response.content, response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Dictionary to store the selected audio features for each URI\n",
    "track_info_dict = {}\n",
    "\n",
    "# Loop to iterate over each URI in the df_uris DataFrame\n",
    "for uri in df_uris['uri']:\n",
    "    track_info = get_track_info(uri)\n",
    "    if track_info:\n",
    "        track_info_dict[uri] = track_info\n",
    "    \n",
    "# convert dictionary into dataframe with uri as the first column\n",
    "track_info_dict = pd.DataFrame.from_dict(track_info_dict, orient='index')\n",
    "track_info_dict.insert(0, 'uri', track_info_dict.index)\n",
    "track_info_dict.reset_index(inplace=True, drop=True)\n",
    "\n",
    "track_info_dict.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/DataAnalyst/Desktop/track_year_duration.csv\"\n",
    "\n",
    "track_info_dict.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {},
   "source": [
    "### Using Spotify's API to get dataframe for external URLs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "these URLs will be used as embedded links in my dashboard to play previews of the selected songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_info(uri):\n",
    "    url = f'{base_url}tracks/{uri}'\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        link_info = response.json()\n",
    "        link_info = {'Spotify URL': link_info['external_urls']}\n",
    "        return link_info\n",
    "    else:\n",
    "        print(f\"Error getting track_info for URI '{uri}': {response.content, response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Dictionary to store the selected audio features for each URI\n",
    "link_info_dict = {}\n",
    "\n",
    "# Loop to iterate over each URI in the df_uris DataFrame\n",
    "for uri in df_uris['uri']:\n",
    "    link_info = get_link_info(uri)\n",
    "    if link_info:\n",
    "        link_info_dict[uri] = link_info\n",
    "    \n",
    "# Convert dictionary into dataframe with uri as the first column\n",
    "link_info_dict = pd.DataFrame.from_dict(link_info_dict, orient='index')\n",
    "link_info_dict.insert(0, 'uri', link_info_dict.index)\n",
    "link_info_dict.reset_index(inplace=True, drop=True)\n",
    "\n",
    "link_info_dict.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "### Merging the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_info_dict = pd.read_csv(r'/Users/DataAnalyst/Desktop/Spotify Data For Tableau/track_info(Year & Duration).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(track_info_dict, link_info_dict, on='uri', how='inner')\n",
    "merged_df.rename(columns={'Spotify URL': 'url'}, inplace=True)\n",
    "merged_df['url'] = merged_df['url'].astype(str)\n",
    "merged_df['url'] = merged_df['url'].str.extract(r'(h.*).{2}$')\n",
    "merged_df['url'] = merged_df['url'].str.replace('com', 'com/embed')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "merged_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/DataAnalyst/Desktop/track_info_url.csv\"\n",
    "\n",
    "merged_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df.merge(audio_features_dict, on='uri')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86",
   "metadata": {},
   "source": [
    "I needed to create a column with the Track Name & Artist name as the uri is different for the same tracks that are released as a single vs the album version. So this new column will be used as the unique identifier instead of the uri column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['track_artist_name'] = merged_df['track_name'] + \"--\" + merged_df['artist_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.read_csv(r'/Users/DataAnalyst/Desktop/Spotify Data For Tableau/Spotify Listening History 2019 - 2022.csv')                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['track_artist_name'] = df_new['track_name'] + \"--\" + df_new['artist_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv(r'/Users/DataAnalyst/Desktop/Spotify Data For Tableau/Spotify Listening History 2019 - 2022.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91",
   "metadata": {},
   "source": [
    "### Adjusting Audio Features Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92",
   "metadata": {},
   "source": [
    "For each unique identifier (Track Name & Artist Name) I need to filter out a unique value for each audio feature, as when creating the dashboard I found that the Spotify algorithm had assigned multiple values for certain audio features for the same song eg. Gvae 2 tempo values for the same Track Name & Artist Name. \n",
    "\n",
    "The code belowe assigns the orginial value of the audio feature if there is only one unique value. Otherwise, it assigns the minimum audio feature value for each Track Name & Artist Name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculated the minimum audio feature for each unique track_artist_name\n",
    "min_acousticness_by_artist = merged_df.groupby('track_artist_name')['acousticness'].transform('min')\n",
    "\n",
    "# used boolean indexing to set adjusted column based on track_artist_name uniqueness\n",
    "merged_df['Acousticness_Adjusted'] = np.where(merged_df['track_artist_name'].nunique() < 2,\n",
    "                                              merged_df['acousticness'],\n",
    "                                              min_acousticness_by_artist)\n",
    "\n",
    "min_speechiness_by_artist = merged_df.groupby('track_artist_name')['speechiness'].transform('min')\n",
    "\n",
    "merged_df['Speechiness_Adjusted'] = np.where(merged_df['track_artist_name'].nunique() < 2,\n",
    "                                             merged_df['speechiness'],\n",
    "                                             min_speechiness_by_artist)\n",
    "\n",
    "min_liveness_by_artist = merged_df.groupby('track_artist_name')['liveness'].transform('min')\n",
    "\n",
    "merged_df['Liveness_Adjusted'] = np.where(merged_df['track_artist_name'].nunique() < 2,\n",
    "                                          merged_df['liveness'],\n",
    "                                          min_liveness_by_artist)\n",
    "\n",
    "min_energy_by_artist = merged_df.groupby('track_artist_name')['energy'].transform('min')\n",
    "\n",
    "merged_df['Energy_Adjusted'] = np.where(merged_df['track_artist_name'].nunique() < 2,\n",
    "                                        merged_df['energy'],\n",
    "                                        min_energy_by_artist)\n",
    "\n",
    "min_danceability_by_artist = merged_df.groupby('track_artist_name')['danceability'].transform('min')\n",
    "\n",
    "merged_df['Danceability_Adjusted'] = np.where(merged_df['track_artist_name'].nunique() < 2,\n",
    "                                              merged_df['danceability'],\n",
    "                                              min_danceability_by_artist)\n",
    "\n",
    "min_valence_by_artist = merged_df.groupby('track_artist_name')['valence'].transform('min')\n",
    "\n",
    "merged_df['Valence_Adjusted'] = np.where(merged_df['track_artist_name'].nunique() < 2,\n",
    "                                         merged_df['valence'],\n",
    "                                         min_valence_by_artist)\n",
    "\n",
    "min_instrumentalness_by_artist = merged_df.groupby('track_artist_name')['instrumentalness'].transform('min')\n",
    "\n",
    "merged_df['Instrumentalness_Adjusted'] = np.where(merged_df['track_artist_name'].nunique() < 2,\n",
    "                                         merged_df['instrumentalness'],\n",
    "                                         min_instrumentalness_by_artist)\n",
    "\n",
    "min_tempo_by_artist = merged_df.groupby('track_artist_name')['tempo'].transform('min')\n",
    "\n",
    "merged_df['Tempo_Adjusted'] = np.where(merged_df['track_artist_name'].nunique() < 2,\n",
    "                                         merged_df['tempo'],\n",
    "                                         min_tempo_by_artist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94",
   "metadata": {},
   "source": [
    "Now I need to drop the old columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df=merged_df.drop(columns=['acousticness',\n",
    "                                  'speechiness',\n",
    "                                  'liveness',\n",
    "                                  'energy',\n",
    "                                  'danceability', \n",
    "                                  'valence', \n",
    "                                  'instrumentalness',\n",
    "                                  'tempo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96",
   "metadata": {},
   "source": [
    "Now I can drop the columns I do not need, as I will be joining these datasets in Tableau with the unique identifier track_artist_name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_number = merged_df.columns.get_loc('key')\n",
    "merged_df = merged_df.iloc[:, column_number:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop_duplicates(subset='track_artist_name', keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99",
   "metadata": {},
   "source": [
    "Now I can save this dataset. I will join all the the saved databases from this code using relationships in the Tableau data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/DataAnalyst/Desktop/merged_audio_features.csv\"\n",
    "\n",
    "merged_df.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
